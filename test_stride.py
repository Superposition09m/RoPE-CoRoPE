"""
æµ‹è¯•ç‰©ç†åŒæŒ‡é’ˆæ–¹æ¡ˆåœ¨ä¸åŒ stride æƒ…å†µä¸‹çš„æ­£ç¡®æ€§
"""

import torch
import sys
import os

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(__file__))

from flash_attn_rope_triton import attention


def test_contiguous():
    """æµ‹è¯•è¿ç»­å†…å­˜ï¼ˆæ­£å¸¸æƒ…å†µï¼‰"""
    print("=" * 80)
    print("æµ‹è¯• 1: è¿ç»­å†…å­˜ (Contiguous)")
    print("=" * 80)
    
    B, H, N, D = 2, 4, 128, 64
    device = 'cuda'
    dtype = torch.float16
    
    q = torch.randn(B, H, N, D, device=device, dtype=dtype)
    k = torch.randn(B, H, N, D, device=device, dtype=dtype)
    v = torch.randn(B, H, N, D, device=device, dtype=dtype)
    freqs_cos = torch.randn(N, D // 2, device=device, dtype=dtype)
    freqs_sin = torch.randn(N, D // 2, device=device, dtype=dtype)
    
    print(f"Q stride: {q.stride()}")
    print(f"K stride: {k.stride()}")
    print(f"V stride: {v.stride()}")
    
    try:
        o = attention(q, k, v, False, 0.5, freqs_cos, freqs_sin, False)
        print(f"âœ… æˆåŠŸï¼è¾“å‡ºå½¢çŠ¶: {o.shape}")
        print(f"   è¾“å‡ºå‡å€¼: {o.mean().item():.4f}, æ ‡å‡†å·®: {o.std().item():.4f}")
        return True
    except Exception as e:
        print(f"âŒ å¤±è´¥: {e}")
        return False


def test_view():
    """æµ‹è¯• view åçš„éè¿ç»­å†…å­˜"""
    print("\n" + "=" * 80)
    print("æµ‹è¯• 2: View åçš„éè¿ç»­å†…å­˜")
    print("=" * 80)
    
    B, H, N, D = 2, 4, 128, 64
    device = 'cuda'
    dtype = torch.float16
    
    # åˆ›å»ºä¸€ä¸ªå¤§çš„ tensorï¼Œç„¶å view æˆæˆ‘ä»¬éœ€è¦çš„å½¢çŠ¶
    q_flat = torch.randn(B * H * N * D, device=device, dtype=dtype)
    k_flat = torch.randn(B * H * N * D, device=device, dtype=dtype)
    v_flat = torch.randn(B * H * N * D, device=device, dtype=dtype)
    
    q = q_flat.view(B, H, N, D)
    k = k_flat.view(B, H, N, D)
    v = v_flat.view(B, H, N, D)
    
    # æ£€æŸ¥æ˜¯å¦è¿ç»­
    print(f"Q is contiguous: {q.is_contiguous()}")
    print(f"Q stride: {q.stride()}")
    
    freqs_cos = torch.randn(N, D // 2, device=device, dtype=dtype)
    freqs_sin = torch.randn(N, D // 2, device=device, dtype=dtype)
    
    try:
        o = attention(q, k, v, False, 0.5, freqs_cos, freqs_sin, False)
        print(f"âœ… æˆåŠŸï¼è¾“å‡ºå½¢çŠ¶: {o.shape}")
        print(f"   è¾“å‡ºå‡å€¼: {o.mean().item():.4f}, æ ‡å‡†å·®: {o.std().item():.4f}")
        return True
    except Exception as e:
        print(f"âŒ å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_transpose():
    """æµ‹è¯• transpose åçš„éè¿ç»­å†…å­˜"""
    print("\n" + "=" * 80)
    print("æµ‹è¯• 3: Transpose åçš„éè¿ç»­å†…å­˜")
    print("=" * 80)
    
    B, H, N, D = 2, 4, 128, 64
    device = 'cuda'
    dtype = torch.float16
    
    # åˆ›å»º [B, H, D, N] ç„¶å transpose æˆ [B, H, N, D]
    q = torch.randn(B, H, D, N, device=device, dtype=dtype).transpose(2, 3)
    k = torch.randn(B, H, D, N, device=device, dtype=dtype).transpose(2, 3)
    v = torch.randn(B, H, D, N, device=device, dtype=dtype).transpose(2, 3)
    
    print(f"Q is contiguous: {q.is_contiguous()}")
    print(f"Q stride: {q.stride()}")
    
    freqs_cos = torch.randn(N, D // 2, device=device, dtype=dtype)
    freqs_sin = torch.randn(N, D // 2, device=device, dtype=dtype)
    
    try:
        o = attention(q, k, v, False, 0.5, freqs_cos, freqs_sin, False)
        print(f"âœ… æˆåŠŸï¼è¾“å‡ºå½¢çŠ¶: {o.shape}")
        print(f"   è¾“å‡ºå‡å€¼: {o.mean().item():.4f}, æ ‡å‡†å·®: {o.std().item():.4f}")
        return True
    except Exception as e:
        print(f"âŒ å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_correctness():
    """æµ‹è¯•æ•°å€¼æ­£ç¡®æ€§ï¼ˆä¸è¿ç»­ç‰ˆæœ¬å¯¹æ¯”ï¼‰"""
    print("\n" + "=" * 80)
    print("æµ‹è¯• 4: æ•°å€¼æ­£ç¡®æ€§éªŒè¯")
    print("=" * 80)
    
    B, H, N, D = 1, 2, 64, 64  # HEAD_DIM å¿…é¡» >= BLOCK_N (64)
    device = 'cuda'
    dtype = torch.float16
    
    # åˆ›å»ºç›¸åŒçš„éšæœºæ•°æ®
    torch.manual_seed(42)
    q_cont = torch.randn(B, H, N, D, device=device, dtype=dtype)
    k_cont = torch.randn(B, H, N, D, device=device, dtype=dtype)
    v_cont = torch.randn(B, H, N, D, device=device, dtype=dtype)
    
    # åˆ›å»ºéè¿ç»­ç‰ˆæœ¬ï¼ˆé€šè¿‡ viewï¼‰
    q_noncont = q_cont.clone().view(B * H * N * D).view(B, H, N, D)
    k_noncont = k_cont.clone().view(B * H * N * D).view(B, H, N, D)
    v_noncont = v_cont.clone().view(B * H * N * D).view(B, H, N, D)
    
    freqs_cos = torch.randn(N, D // 2, device=device, dtype=dtype)
    freqs_sin = torch.randn(N, D // 2, device=device, dtype=dtype)
    
    try:
        o_cont = attention(q_cont, k_cont, v_cont, False, 0.5, freqs_cos, freqs_sin, False)
        o_noncont = attention(q_noncont, k_noncont, v_noncont, False, 0.5, freqs_cos, freqs_sin, False)
        
        diff = torch.abs(o_cont - o_noncont).max().item()
        print(f"è¿ç»­ vs éè¿ç»­æœ€å¤§å·®å¼‚: {diff:.6e}")
        
        if diff < 1e-3:
            print(f"âœ… æ•°å€¼æ­£ç¡®æ€§éªŒè¯é€šè¿‡ï¼")
            return True
        else:
            print(f"âš ï¸  å·®å¼‚è¾ƒå¤§ï¼Œå¯èƒ½éœ€è¦æ£€æŸ¥")
            return False
    except Exception as e:
        print(f"âŒ å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    print("=" * 80)
    print("ç‰©ç†åŒæŒ‡é’ˆ Stride æµ‹è¯•")
    print("=" * 80)
    
    results = {}
    results['contiguous'] = test_contiguous()
    results['view'] = test_view()
    results['transpose'] = test_transpose()
    results['correctness'] = test_correctness()
    
    print("\n" + "=" * 80)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 80)
    for test_name, passed in results.items():
        status = "âœ… é€šè¿‡" if passed else "âŒ å¤±è´¥"
        print(f"  {test_name}: {status}")
    
    all_passed = all(results.values())
    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Stride å¤„ç†æ­£ç¡®ã€‚")
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥ stride å¤„ç†é€»è¾‘ã€‚")
    
    sys.exit(0 if all_passed else 1)

